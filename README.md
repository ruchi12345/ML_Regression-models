# ML_Regression-models
## Machine learning:

Machine learning is a part of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience.The main focus of machine learning is to develop the computer programs.ML are those that can learn from data and improve from experience, without human intervention.Â Learning tasks may include learning the function that maps the input to the output. To select the right alogritm is key part of ml.

## Supervised learning:
supervised learning use labeled training data to learn the mapping function from the input variable to the output variable.

Supervised learning can be of two types:

## 1.Classification:
To predict the outcome of a given sample where the output variable is in the form of categories
## 2.Regression:
To predict the outcome of a given sample where the output variable is in the form of real values.

## The algorithms we cover in this blog is:
1.Linear Regression

2.Support vector machine with regression(SVR)

3.Random Forest Regression

4.Decision Tree Regressor  are the example of supervised learning.

## Linear Regression:

This Regression algorithm finds the relationship between dependent variable and independent variable. We have set of input variable that are used to identify the output variable.The goal of ML is to quantify this relationship.
Linear Regression is represented as a line in the form of y = a + bx.

## Support vector Machine-Regression(SVR):

Support Vector Machine can also be used as a regression method,The Support Vector Regression (SVR) uses the same principles as the SVM for classification, with only a few minor differences.First of all, because output is a real number it becomes very difficult to predict the information at hand, which has infinite possibilities.It create hyperpalne with maximum margin from support vectors.

## Random Forest Regression:

Random forest creates multiple decision trees on randomly selected data samples, then merge that trees for the accurate and stable output. It is flexible and easy to use alogrihtm.As the name suggest it create forest of trees,features are the root nodes and subnodes are the trees created by the random forest.

## Decision Tree Regressor:

A decision tree is graphical represention of all the possible solutions to a decision tree based on certain conditions. It is decision tress because it start with a single root it create tree for the best fir output.

## Polynomial Regression:

It is a technique to fit a nonlinear equation by taking polynomial functions of independent variable.There are some relationships that a researcher will hypothesize is curvilinear. Clearly, such type of cases will include a polynomial term.

## Ridge Regression:
Ridge regression is for reduce the complexity of model that is number of predictors.Removing predictors from the model can be seen as settings their coefficients to zero. Instead of forcing them to be exactly zero.
